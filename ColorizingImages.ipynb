{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KorneliuszDyszczynski/ColorizingPhotosNeuralNetwork/blob/master/ColorizingImages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEp-nCelNPlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ab9342-34f3-411a-ce96-6eb3d0238e21"
      },
      "source": [
        "!rm -r ../Humans2/*"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '../Humans2/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t1IhjOUz-4j"
      },
      "source": [
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "api.dataset_download_files('ashwingupta3012/human-faces')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIJojRPmeMsz"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import keras.preprocessing.image\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
        "from keras.layers import Conv2D, UpSampling2D, InputLayer\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "from matplotlib.pyplot import imsave"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-6qvkU33gES"
      },
      "source": [
        "!unzip human-faces.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5NRcVqFsVhQ"
      },
      "source": [
        "os.chdir('/content/Humans/') \n",
        "path='/content/Humans/'\n",
        "path2='/content/Humans2/'\n",
        "path3='/content/'\n",
        "COUNT =0\n",
        "w = 200\n",
        "h = 200\n",
        "stop=10;\n",
        "\n",
        "# for f in os.listdir():\n",
        "#     f_name, f_ext = os.path.splitext(f)\n",
        "#     f_name = \"face\" + str(COUNT) \n",
        "#     COUNT = COUNT + 1\n",
        "#     new_name = '{}{}'.format(f_name, f_ext)\n",
        "#     os.rename(f, new_name)\n",
        "\n",
        "for f in os.listdir():\n",
        "    COUNT = COUNT + 1\n",
        "    if(COUNT<stop):\n",
        "      im = Image.open(path+f)\n",
        "      im = im.resize((w, h))\n",
        "      im = im.convert('RGB')\n",
        "      im.save(path2+\"resized\"+f)\n",
        "\n",
        "os.chdir('/content/Humans2/') \n",
        "\n",
        "images = [Image.open(f) for f in os.listdir()]\n",
        "widths, heights = zip(*(i.size for i in images))\n",
        "\n",
        "total_width = sum(widths)\n",
        "max_height = max(heights)\n",
        "\n",
        "new_im = Image.new('RGB', (total_width, max_height))\n",
        "\n",
        "# x_offset = 0\n",
        "# for im in images:\n",
        "#   new_im.paste(im, (x_offset,0))\n",
        "#   x_offset += im.size[0]\n",
        "\n",
        "# new_im.save(path3+'test.jpg')\n",
        "\n",
        "\n",
        "# image = img_to_array(load_img(path3+'test.jpg'))\n",
        "# image = np.array(image, dtype=float)\n",
        "\n",
        "# Get images\n",
        "X = []\n",
        "for filename in os.listdir('/content/Humans2/'):\n",
        "    X.append(img_to_array(load_img('/content/Humans2/'+filename)))\n",
        "X = np.array(X, dtype=float)\n",
        "# Set up training and test data\n",
        "split = int(0.95*len(X))\n",
        "Xtrain = X[:split]\n",
        "Xtrain = 1.0/255*Xtrain\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA7pYxZ8cdJ9"
      },
      "source": [
        "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=20,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "batch_size = 50\n",
        "def image_a_b_gen(batch_size):\n",
        "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 100\n",
        "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FofoHeS6t-B_"
      },
      "source": [
        "# X = rgb2lab(1.0/255*image)[:,:,0]\n",
        "# Y = rgb2lab(1.0/255*image)[:,:,1:]\n",
        "# Y = Y / 128\n",
        "# witdthvar=(stop-1)*200;\n",
        "# X = X.reshape(1, 200, witdthvar, 1)\n",
        "# Y = Y.reshape(1, 200, witdthvar, 2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3sthVl6wL4i"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(200, 200, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='mse')"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eC2KTL1wcov",
        "outputId": "0e764535-08bc-453b-acf1-2deb8c81b7b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit_generator(image_a_b_gen(batch_size), steps_per_epoch=40, epochs=2)\n",
        "# print(model.evaluate(X, Y, batch_size=5000))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.0089\n",
            "Epoch 2/2\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.0064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f606a5cb990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBTewTlkGK-9"
      },
      "source": [
        "color_me = []\n",
        "# for filename in os.listdir('/Test/'):\n",
        "#         color_me.append(img_to_array(load_img('/Test/'+filename)))\n",
        "color_me.append(img_to_array(load_img('/Test/woman_smoll.jpg')))\n",
        "color_me = np.array(color_me, dtype=float)\n",
        "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
        "color_me = color_me.reshape(color_me.shape+(1,))\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lrFje9UwnHK"
      },
      "source": [
        "output = model.predict(color_me)\n",
        "output = output * 128\n",
        "\n",
        "for i in range(len(output)):\n",
        "        cur = np.zeros((200, 200, 3))\n",
        "        cur[:,:,0] = color_me[i][:,:,0]\n",
        "        cur[:,:,1:] = output[i]\n",
        "        imsave(path3+\"img_result.png\", lab2rgb(cur))\n",
        "\n",
        "\n",
        "# canvas = np.zeros((200, 200, 3))\n",
        "# canvas[:,:,0] = color_me[0][:,:,0]\n",
        "# canvas[:,:,1:] = output[0]\n",
        "# imsave(path3+\"img_result.png\", lab2rgb(canvas))\n",
        "# imsave(path3+\"img_gray_scale.png\", rgb2gray(lab2rgb(canvas)))\n"
      ],
      "execution_count": 76,
      "outputs": []
    }
  ]
}