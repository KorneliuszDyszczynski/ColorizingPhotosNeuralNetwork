{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KolorajzerV2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0XXe4hlmLG95gLpXrhNxV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KorneliuszDyszczynski/ColorizingPhotosNeuralNetwork/blob/PlanA2/KolorajzerV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJLYN8DJNt3f"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "api.dataset_download_files('theblackmamba31/landscape-image-colorization')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJP0YMo_OPKM"
      },
      "source": [
        "!unzip landscape-image-colorization.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFbTc4BNOtvJ"
      },
      "source": [
        "!mv landscape\\ Images/color data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYBP3hE6ohXg"
      },
      "source": [
        "!rm -r results\n",
        "!mkdir results"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrBsQcQS3lRC"
      },
      "source": [
        "!mv landscape\\ Images/gray/* test/"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS9xmEWu74Lp"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.engine import Layer\n",
        "from keras.layers import Conv2D, Conv3D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Sequential, Model\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave\n",
        "from time import time\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageFile"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAcAIobI8Dow"
      },
      "source": [
        "path = '//content/data/'\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpUtnoRpT22b"
      },
      "source": [
        "vggmodel = keras.applications.vgg16.VGG16()\n",
        "newmodel = Sequential() \n",
        "num = 0\n",
        "for i, layer in enumerate(vggmodel.layers):\n",
        "    if i<19:\n",
        "      newmodel.add(layer)\n",
        "newmodel.summary()\n",
        "for layer in newmodel.layers:\n",
        "  layer.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK2ApT8__DXq",
        "outputId": "c91a95a9-7826-4026-82d5-a88a293cc9f8"
      },
      "source": [
        "train = train_datagen.flow_from_directory(path, target_size=(224, 224),batch_size=2000,class_mode=None)\n",
        "\n",
        "X =[]\n",
        "Y =[]\n",
        "for img in train[0]:\n",
        "  try:\n",
        "      lab = rgb2lab(img)\n",
        "      X.append(lab[:,:,0])\n",
        "      Y.append(lab[:,:,1:] / 128)\n",
        "  except:\n",
        "     print('error')\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "X = X.reshape(X.shape+(1,))\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7129 images belonging to 1 classes.\n",
            "(2000, 224, 224, 1)\n",
            "(2000, 224, 224, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAbGi4F3SPPt",
        "outputId": "01a83e33-0580-4108-8f99-446a375e84b5"
      },
      "source": [
        "vggfeatures = []\n",
        "for i, sample in enumerate(X):\n",
        "  sample = gray2rgb(sample)\n",
        "  sample = sample.reshape((1,224,224,3))\n",
        "  prediction = newmodel.predict(sample)\n",
        "  prediction = prediction.reshape((7,7,512))\n",
        "  vggfeatures.append(prediction)\n",
        "vggfeatures = np.array(vggfeatures)\n",
        "print(vggfeatures.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 7, 7, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqHpELoE8ov6"
      },
      "source": [
        "#Encoder\n",
        "encoder_input = Input(shape=(7, 7, 512,))\n",
        "#Decoder\n",
        "decoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_input)\n",
        "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "model = Model(inputs=encoder_input, outputs=decoder_output)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzoF332r8rOj"
      },
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "tensorboard = TensorBoard(log_dir='//content/logs/')\n",
        "model.compile(optimizer='Adam', loss='mse' , metrics=['accuracy'])\n",
        "model.fit(vggfeatures, Y, verbose=1, epochs=1000, batch_size=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHXUCjJpG-qS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6106a6e0-a75e-4b01-9d7a-df2ac77f36aa"
      },
      "source": [
        "!rm -r //content/test/.ipynb_checkpoints"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '//content/test/.ipynb_checkpoints': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1WB_8rX8uBO"
      },
      "source": [
        "testpath = '//content/test/'\n",
        "files = os.listdir(testpath)\n",
        "for idx, file in enumerate(files):\n",
        "    test = img_to_array(load_img(testpath+file))\n",
        "    test = resize(test, (224,224), anti_aliasing=True)\n",
        "    test*= 1.0/255\n",
        "    lab = rgb2lab(test)\n",
        "    l = lab[:,:,0]\n",
        "    L = gray2rgb(l)\n",
        "    L = L.reshape((1,224,224,3))\n",
        "    #print(L.shape)\n",
        "    vggpred = newmodel.predict(L)\n",
        "    ab = model.predict(vggpred)\n",
        "    #print(ab.shape)\n",
        "    ab = ab*128\n",
        "    cur = np.zeros((224, 224, 3))\n",
        "    cur[:,:,0] = l\n",
        "    cur[:,:,1:] = ab\n",
        "    imsave('//content/results/'+str(idx)+\".jpg\", lab2rgb(cur))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}